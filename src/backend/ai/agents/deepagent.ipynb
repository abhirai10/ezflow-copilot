{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378188e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from deepagents import create_deep_agent\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from prompts import RESEARCH_INSTRUCTION\n",
    "\n",
    "\n",
    "load_dotenv(os.path.join(\"../../..\", \".env\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e8a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=getenv(\"MODEL_API_KEY\"),\n",
    ")\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=RESEARCH_INSTRUCTION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e0b37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cd7b6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is langgraph?', additional_kwargs={}, response_metadata={}, id='ed858d21-a97c-4f8d-bb72-0623162a7a69'),\n",
       "  AIMessage(content='**LangGraph** is an open‑source Python library designed to help developers build **stateful, multi‑agent, and workflow‑oriented applications** on top of large language models (LLMs). It was created by the team behind **LangChain**, and it extends the ideas of graph‑based execution to make it easier to coordinate complex sequences of LLM calls, tool usage, memory, and other side‑effects.\\n\\n### Key Concepts\\n\\n| Concept | What it Means |\\n|---------|---------------|\\n| **Graph‑based workflow** | You define a directed graph where nodes represent steps (e.g., LLM calls, Python code, external API calls) and edges represent the flow of data. This gives you a visual, programmable way to orchestrate complex pipelines. |\\n| **Stateful agents** | Nodes can maintain and propagate state across multiple turns, enabling agents that remember past interactions, keep context, and can be paused/resumed. |\\n| **Persistence** | Graph state can be saved to a variety of backends (e.g., SQLite, PostgreSQL, Redis), so workflows survive process restarts and can be resumed later. |\\n| **Compiled execution** | Once a graph is defined, it can be “compiled” into an executable workflow that runs deterministically, making debugging and testing easier. |\\n| **Modular & composable** | You can build reusable sub‑graphs (sub‑workflows) and compose them into larger pipelines, supporting both simple chains and branching/looping logic. |\\n| **Extensible tooling** | LangGraph integrates with LangChain’s tooling (LLMs, embeddings, retrieval, etc.) as well as generic Python functions, allowing you to plug in custom tooling. |\\n| **Async & streaming** | Supports asynchronous execution and streaming of tokens, which is useful for building interactive chat experiences or real‑time pipelines. |\\n\\n### Typical Use‑Cases\\n\\n| Use‑Case | How LangGraph Helps |\\n|----------|----------------------|\\n| **Conversational agents with memory** | Create a graph that stores conversation history, routes user inputs through different reasoning steps, and retains state across turns. |\\n| **Multi‑agent collaboration** | Define multiple agent nodes that can call each other, exchange information, and coordinate tasks (e.g., planner → executor → reviewer). |\\n| **Complex pipelines** | Build workflows that involve retrieval, LLM reasoning, external API calls, data transformation, and branching decisions. |\\n| **Model‑driven UI flows** | Wire up a graph to power interactive editors, code assistants, or data‑analysis assistants where each step may trigger different UI components. |\\n| **Testing & evaluation** | Because the workflow is a deterministic graph, you can unit‑test individual nodes or the entire pipeline and reproduce failures consistently. |\\n\\n### Simple Example (Python)\\n\\n```python\\nfrom langgraph import Graph, END\\nfrom langchain.schema import Message\\n\\n# Define a simple workflow: ask → generate → respond\\ndef ask_user(state):\\n    # Grab the latest user message\\n    return {\"input\": state[\"messages\"][-1].content}\\n\\ndef generate_answer(state):\\n    # Call an LLM (e.g., ChatGPT) using LangChain\\n    from langchain.chat_models import ChatOpenAI\\n    llm = ChatOpenAI(model=\"gpt-4\")\\n    answer = llm.predict(input=state[\"input\"])\\n    return {\"answer\": answer}\\n\\ndef respond(state):\\n    # Send the answer back to the user\\n    return {\"output\": state[\"answer\"]}\\n\\n# Create the graph\\ngraph = Graph(\\n    nodes={\\n        \"ask\": ask_user,\\n        \"generate\": generate_answer,\\n        \"respond\": respond,\\n    },\\n    edges=[\\n        (\"ask\", \"generate\"),\\n        (\"generate\", \"respond\"),\\n    ],\\n)\\n\\n# Compile and run\\ncompiled = graph.compile()\\ninitial_state = {\"messages\": [Message(role=\"user\", content=\"What is LangGraph?\")]}\\nresult = compiled(initial_state)\\nprint(result[\"output\"])\\n```\\n\\nIn this tiny example, a user’s question flows through three nodes, with state (`messages`) persisting across calls. In real applications you’d add branching logic, memory persisting, loops, and more complex branching/parallelism.\\n\\n### When to Use LangGraph\\n\\n- **You need a visual, programmable way to orchestrate LLM calls and external tools.**  \\n- **Your workflow requires state to be preserved across multiple turns** (e.g., chat bots, iterative planners).  \\n- **You want reproducibility, testability, and version control** over the execution flow.  \\n- **You’re building multi‑agent systems** where agents need to call each other or coordinate tasks.  \\n- **You want to keep the implementation framework‑agnostic** (you can use LangChain, LangFlow, or plain Python).  \\n\\n### Getting Started\\n\\n1. **Install**: `pip install langgraph` (and optionally `langchain` for LLM integrations).  \\n2. **Read the docs**: https://langb.github.io/langgraph/ – it includes guides, API reference, and tutorials.  \\n3. **Explore examples**: The repo contains starter templates for chat agents, planners, and retrieval‑augmented pipelines.  \\n4. **Deploy**: Graph state can be persisted locally or to cloud databases, enabling production‑grade, long‑running workflows.\\n\\nIn short, **LangGraph** provides a robust, graph‑oriented framework for constructing sophisticated LLM‑driven applications that need multi‑step reasoning, memory, and orchestrated tool usage. It bridges the gap between simple one‑shot LLM calls and fully fledged autonomous AI agents.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1310, 'prompt_tokens': 5165, 'total_tokens': 6475, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 153, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'nvidia/nemotron-3-nano-30b-a3b:free', 'system_fingerprint': None, 'id': 'gen-1768061035-zFOZ7FOTMPtQi86rHxlc', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba8a6-6340-7ce2-8da8-8e658e64a568-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 5165, 'output_tokens': 1310, 'total_tokens': 6475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 153}})]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554e6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "conn_str = \"mssql+pyodbc:///?odbc_connect=Driver={ODBC Driver 18 for SQL Server};Server=tcp:underwriting-accelerator-sqlserver.database.windows.net,1433;Database=free-sql-db-8814968;Uid=abhishek_admin;Pwd=ygN8dO15e9BBQ4a6;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=120\"\n",
    "\n",
    "engine = create_engine(conn_str, pool_pre_ping=True, pool_size=5)\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2c2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "query = text(\"Select count(1) from Submissions\")\n",
    "\n",
    "v = db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29134d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "\n",
      "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "\n",
      "sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\n",
      "\n",
      "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=model)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"{tool.name}: {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ed973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import SQL_ANALYST_AGENT_PROMPT\n",
    "\n",
    "system_prompt = SQL_ANALYST_AGENT_PROMPT.format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c82b9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlagent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84da13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which is submission count?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which is submission count?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_22d82ae47a7345a3831f4ff6)\n",
      " Call ID: call_22d82ae47a7345a3831f4ff6\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "SubmissionDocuments, Submissions, underwriting_rules\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_019a1bf50f71428992a84a6c)\n",
      " Call ID: call_019a1bf50f71428992a84a6c\n",
      "  Args:\n",
      "    table_names: Submissions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE [Submissions] (\n",
      "\t[SubmissionID] UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \n",
      "\t[SubmissionNo] VARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[InsuredName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[BrokerName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[CedantName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[Department] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ProfitCenter] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[LineOfBusiness] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[TotalSumInsured] DECIMAL(18, 2) NULL, \n",
      "\t[EffectiveDate] DATE NULL, \n",
      "\t[ExpiryDate] DATE NULL, \n",
      "\t[OverAllStatus] VARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NULL DEFAULT ('Draft'), \n",
      "\t[Underwriter] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[TechnicalAssistant] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[UnderwritingYear] INTEGER NULL, \n",
      "\t[CreatedBy] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[CreatedAt] DATETIME NULL DEFAULT (getdate()), \n",
      "\t[UpdatedAt] DATETIME NULL DEFAULT (getdate()), \n",
      "\tCONSTRAINT [PK__Submissi__449EE1051AB96F95] PRIMARY KEY CLUSTERED ([SubmissionID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Submissions table:\n",
      "SubmissionID\tSubmissionNo\tInsuredName\tBrokerName\tCedantName\tDepartment\tProfitCenter\tLineOfBusiness\tTotalSumInsured\tEffectiveDate\tExpiryDate\tOverAllStatus\tUnderwriter\tTechnicalAssistant\tUnderwritingYear\tCreatedBy\tCreatedAt\tUpdatedAt\n",
      "c8fd9ded-a7f0-403d-bfc4-0d950b81b347\tAO3678-2026-S\ttest\tMarsh\tSwiss Re\tEnergy\tPC-LDN-02 (London)\t\t33330.00\t2026-01-04\t2026-01-16\tDraft\tJohn Doe\tDonna Paulsen\t2026\tABHISHEK RAI\t2026-01-04 08:14:37.447000\t2026-01-04 08:14:37.447000\n",
      "30e26599-fb24-429c-8c6e-16b48afc7f3f\tWZ2361-2026-S\tTest\tAon\tSwiss Re\tEnergy\tPC-LDN-02 (London)\t\t60000.00\t2026-01-04\t2026-01-04\tDraft\tJohn Doe\tRachel Zane\t2026\tABHISHEK RAI\t2026-01-04 07:52:03.393000\t2026-01-04 07:52:03.393000\n",
      "5ef63283-bcd9-4d33-8044-4aa8551025dc\tQX4816-2025-S\tABC\tXYZ\tAditya Birla\tProperty\tTreaty Property\t\t50000.00\t2025-12-26\t2025-12-26\tDraft\tAbhishek Rai\tBhavin Dimmer\t2025\tABHISHEK RAI\t2025-12-26 08:43:55.990000\t2025-12-26 08:43:55.990000\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_c53b13cfcbcc454c894ce366)\n",
      " Call ID: call_c53b13cfcbcc454c894ce366\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) AS SubmissionCount FROM Submissions;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "SELECT COUNT(*) AS SubmissionCount FROM Submissions;\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_4741279d805440f6b2e6e5ff)\n",
      " Call ID: call_4741279d805440f6b2e6e5ff\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) AS SubmissionCount FROM Submissions;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[(3,)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The **Submissions** table contains **3** records, so the submission count is **3**.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which is submission count?\"\n",
    "\n",
    "for step in sqlagent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55369a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=sqlagent.invoke( {\"messages\": [{\"role\": \"user\", \"content\": question}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b1db328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The **Submissions** table currently contains **3** records. Therefore, the submission count is **3**. If you were looking for a specific column named “submission count,” the table does not have one—so we infer the count by counting the rows, which yields 3.\n"
     ]
    }
   ],
   "source": [
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc6c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware \n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "\n",
    "sqlagentwithinterupt = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    middleware=[ \n",
    "        HumanInTheLoopMiddleware( \n",
    "            interrupt_on={\"sql_db_query\": True}, \n",
    "            description_prefix=\"Tool execution pending approval\", \n",
    "        ), \n",
    "    ], \n",
    "    checkpointer=InMemorySaver(), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbbbd09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which is submission count?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which is submission count?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_b7fde1fd2c1c400189a33ddd)\n",
      " Call ID: call_b7fde1fd2c1c400189a33ddd\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "SubmissionDocuments, Submissions, underwriting_rules\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_dc0e2106268b4cc0a2a82bec)\n",
      " Call ID: call_dc0e2106268b4cc0a2a82bec\n",
      "  Args:\n",
      "    table_names: Submissions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE [Submissions] (\n",
      "\t[SubmissionID] UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \n",
      "\t[SubmissionNo] VARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[InsuredName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[BrokerName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[CedantName] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[Department] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ProfitCenter] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[LineOfBusiness] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[TotalSumInsured] DECIMAL(18, 2) NULL, \n",
      "\t[EffectiveDate] DATE NULL, \n",
      "\t[ExpiryDate] DATE NULL, \n",
      "\t[OverAllStatus] VARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NULL DEFAULT ('Draft'), \n",
      "\t[Underwriter] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[TechnicalAssistant] VARCHAR(100) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[UnderwritingYear] INTEGER NULL, \n",
      "\t[CreatedBy] VARCHAR(255) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[CreatedAt] DATETIME NULL DEFAULT (getdate()), \n",
      "\t[UpdatedAt] DATETIME NULL DEFAULT (getdate()), \n",
      "\tCONSTRAINT [PK__Submissi__449EE1051AB96F95] PRIMARY KEY CLUSTERED ([SubmissionID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Submissions table:\n",
      "SubmissionID\tSubmissionNo\tInsuredName\tBrokerName\tCedantName\tDepartment\tProfitCenter\tLineOfBusiness\tTotalSumInsured\tEffectiveDate\tExpiryDate\tOverAllStatus\tUnderwriter\tTechnicalAssistant\tUnderwritingYear\tCreatedBy\tCreatedAt\tUpdatedAt\n",
      "c8fd9ded-a7f0-403d-bfc4-0d950b81b347\tAO3678-2026-S\ttest\tMarsh\tSwiss Re\tEnergy\tPC-LDN-02 (London)\t\t33330.00\t2026-01-04\t2026-01-16\tDraft\tJohn Doe\tDonna Paulsen\t2026\tABHISHEK RAI\t2026-01-04 08:14:37.447000\t2026-01-04 08:14:37.447000\n",
      "30e26599-fb24-429c-8c6e-16b48afc7f3f\tWZ2361-2026-S\tTest\tAon\tSwiss Re\tEnergy\tPC-LDN-02 (London)\t\t60000.00\t2026-01-04\t2026-01-04\tDraft\tJohn Doe\tRachel Zane\t2026\tABHISHEK RAI\t2026-01-04 07:52:03.393000\t2026-01-04 07:52:03.393000\n",
      "5ef63283-bcd9-4d33-8044-4aa8551025dc\tQX4816-2025-S\tABC\tXYZ\tAditya Birla\tProperty\tTreaty Property\t\t50000.00\t2025-12-26\t2025-12-26\tDraft\tAbhishek Rai\tBhavin Dimmer\t2025\tABHISHEK RAI\t2025-12-26 08:43:55.990000\t2025-12-26 08:43:55.990000\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_4c766a711ead4f48ace1eb7c)\n",
      " Call ID: call_4c766a711ead4f48ace1eb7c\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) AS SubmissionCount FROM Submissions\n",
      "INTERRUPTED:\n",
      "Tool execution pending approval\n",
      "\n",
      "Tool: sql_db_query\n",
      "Args: {'query': 'SELECT COUNT(*) AS SubmissionCount FROM Submissions'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Which is submission count?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}} \n",
    "\n",
    "for step in sqlagentwithinterupt.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    config, \n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if \"__interrupt__\" in step: \n",
    "        print(\"INTERRUPTED:\") \n",
    "        interrupt = step[\"__interrupt__\"][0] \n",
    "        for request in interrupt.value[\"action_requests\"]: \n",
    "            print(request[\"description\"]) \n",
    "    elif \"messages\" in step:\n",
    "        step[\"messages\"][-1].pretty_print()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c28fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_4c766a711ead4f48ace1eb7c)\n",
      " Call ID: call_4c766a711ead4f48ace1eb7c\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) AS SubmissionCount FROM Submissions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_4c766a711ead4f48ace1eb7c)\n",
      " Call ID: call_4c766a711ead4f48ace1eb7c\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) AS SubmissionCount FROM Submissions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[(3,)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The table **Submissions** contains **3** records, so the submission count is **3**.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command \n",
    "\n",
    "for step in sqlagentwithinterupt.stream(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), \n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if \"messages\" in step:\n",
    "        step[\"messages\"][-1].pretty_print()\n",
    "    elif \"__interrupt__\" in step:\n",
    "        print(\"INTERRUPTED:\")\n",
    "        interrupt = step[\"__interrupt__\"][0]\n",
    "        for request in interrupt.value[\"action_requests\"]:\n",
    "            print(request[\"description\"])\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezflow-copilot (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
